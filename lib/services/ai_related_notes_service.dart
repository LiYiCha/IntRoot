import 'dart:convert';
import 'dart:math';

import 'package:flutter/foundation.dart';
import 'package:http/http.dart' as http;
import 'package:inkroot/config/app_config.dart';
import 'package:inkroot/models/note_model.dart';
import 'package:shared_preferences/shared_preferences.dart';

/// ğŸš€ AI ç›¸å…³ç¬”è®°æœåŠ¡ - è¶…è¶Šå¤§å‚ç‰ˆ
///
/// æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„æ¨¡å‹ï¼Œè‡ªåŠ¨ä½¿ç”¨æœ€ä½³ç­–ç•¥ï¼š
/// - OpenAI æ¨¡å‹ï¼šä½¿ç”¨ Embedding APIï¼ˆé«˜ç²¾åº¦å‘é‡ç›¸ä¼¼åº¦ï¼‰
/// - DeepSeek/å…¶ä»–ï¼šä½¿ç”¨ Chat APIï¼ˆAI æ™ºèƒ½è¯­ä¹‰åˆ†æï¼‰
class AIRelatedNotesService {
  // ğŸš€ ä½¿ç”¨ç»Ÿä¸€é…ç½®ç®¡ç†
  static const String _cachePrefix = AppConfig.noteCachePrefix;
  static final Duration _cacheExpiry = Duration(hours: AppConfig.aiRelatedNotesCacheHours);

  /// æŸ¥æ‰¾ç›¸å…³ç¬”è®° - æ™ºèƒ½è·¯ç”±
  Future<List<RelatedNote>> findRelatedNotes({
    required Note currentNote,
    required List<Note> allNotes,
    required String apiKey,
    required String apiUrl,
    required String model,
    int topK = 5,
  }) async {
    try {
      debugPrint('ğŸ” AIç›¸å…³ç¬”è®°åˆ†æå¼€å§‹...');
      debugPrint('ğŸ“‹ å½“å‰ç¬”è®°ID: ${currentNote.id}');
      debugPrint('ğŸ¤– ä½¿ç”¨æ¨¡å‹: $model');

      // æ£€æŸ¥ç¼“å­˜
      final cacheKey =
          '${currentNote.id}_${currentNote.updatedAt.millisecondsSinceEpoch}';
      final cachedResult = await _getCachedResult(cacheKey);
      if (cachedResult != null) {
        debugPrint('ğŸ’¾ ä½¿ç”¨ç¼“å­˜ç»“æœ');
        return _parseRelatedNotes(cachedResult, allNotes).take(topK).toList();
      }

      List<RelatedNote> relatedNotes;

      // æ ¹æ®æ¨¡å‹é€‰æ‹©ç­–ç•¥
      if (_isOpenAIModel(model, apiUrl)) {
        debugPrint('âœ¨ ä½¿ç”¨ OpenAI Embedding ç­–ç•¥');
        relatedNotes = await _findByEmbedding(
          currentNote: currentNote,
          allNotes: allNotes,
          apiKey: apiKey,
          apiUrl: apiUrl,
          topK: topK,
        );
      } else {
        debugPrint('ğŸ§  ä½¿ç”¨ AI æ™ºèƒ½åˆ†æç­–ç•¥');
        relatedNotes = await _findByAIAnalysis(
          currentNote: currentNote,
          allNotes: allNotes,
          apiKey: apiKey,
          apiUrl: apiUrl,
          model: model,
          topK: topK,
        );
      }

      // ç¼“å­˜ç»“æœ
      if (relatedNotes.isNotEmpty) {
        await _cacheResult(cacheKey, relatedNotes);
      }

      debugPrint('âœ… æ‰¾åˆ° ${relatedNotes.length} æ¡ç›¸å…³ç¬”è®°');
      return relatedNotes;
    } catch (e) {
      debugPrint('âŒ æŸ¥æ‰¾ç›¸å…³ç¬”è®°å¤±è´¥: $e');
      return [];
    }
  }

  /// åˆ¤æ–­æ˜¯å¦ä¸º OpenAI æ¨¡å‹
  bool _isOpenAIModel(String model, String apiUrl) =>
      apiUrl.contains('openai.com') ||
      model.startsWith('gpt-') ||
      model.contains('text-embedding');

  /// ç­–ç•¥1ï¼šä½¿ç”¨ OpenAI Embedding APIï¼ˆé«˜ç²¾åº¦ï¼‰
  Future<List<RelatedNote>> _findByEmbedding({
    required Note currentNote,
    required List<Note> allNotes,
    required String apiKey,
    required String apiUrl,
    required int topK,
  }) async {
    try {
      // è·å–å½“å‰ç¬”è®°çš„å‘é‡
      final currentVector = await _getEmbedding(
        text: _cleanText(currentNote.content),
        apiKey: apiKey,
        apiUrl: apiUrl,
      );

      if (currentVector == null) {
        debugPrint('âš ï¸ è·å–å‘é‡å¤±è´¥ï¼Œé™çº§ä¸ºæœ¬åœ°ç®—æ³•');
        return _findByLocalAlgorithm(currentNote, allNotes, topK);
      }

      final results = <RelatedNote>[];

      // è®¡ç®—æ¯ä¸ªç¬”è®°çš„ç›¸ä¼¼åº¦
      for (final note in allNotes) {
        if (note.id == currentNote.id || note.content.trim().isEmpty) continue;

        final noteVector = await _getEmbedding(
          text: _cleanText(note.content),
          apiKey: apiKey,
          apiUrl: apiUrl,
        );

        if (noteVector != null) {
          final similarity = _cosineSimilarity(currentVector, noteVector);
          if (similarity > 0.5) {
            results.add(RelatedNote(note: note, similarity: similarity));
          }
        }
      }

      results.sort((a, b) => b.similarity.compareTo(a.similarity));
      return results.take(topK).toList();
    } catch (e) {
      debugPrint('âŒ Embedding ç­–ç•¥å¤±è´¥: $e');
      return _findByLocalAlgorithm(currentNote, allNotes, topK);
    }
  }

  /// è·å–æ–‡æœ¬å‘é‡
  Future<List<double>?> _getEmbedding({
    required String text,
    required String apiKey,
    required String apiUrl,
  }) async {
    try {
      final response = await http
          .post(
            Uri.parse('$apiUrl/embeddings'),
            headers: {
              'Content-Type': 'application/json',
              'Authorization': 'Bearer $apiKey',
            },
            body: json.encode({
              'model': 'text-embedding-3-small',
              'input': text.substring(0, min(text.length, 2000)),
            }),
          )
          .timeout(const Duration(seconds: 10));

      if (response.statusCode == 200) {
        final data = json.decode(response.body);
        return List<double>.from(data['data'][0]['embedding']);
      }
      return null;
    } catch (e) {
      return null;
    }
  }

  /// ç­–ç•¥2ï¼šä½¿ç”¨ Chat API è¿›è¡Œæ™ºèƒ½åˆ†æï¼ˆDeepSeek ç­‰ï¼‰
  Future<List<RelatedNote>> _findByAIAnalysis({
    required Note currentNote,
    required List<Note> allNotes,
    required String apiKey,
    required String apiUrl,
    required String model,
    required int topK,
  }) async {
    try {
      // å‡†å¤‡å€™é€‰ç¬”è®°ï¼ˆæœ€å¤š30æ¡ï¼Œé¿å… token è¿‡å¤šï¼‰
      final candidates = allNotes
          .where((n) => n.id != currentNote.id && n.content.trim().isNotEmpty)
          .take(30)
          .toList();

      if (candidates.isEmpty) return [];

      // æ„å»º AI åˆ†æçš„ prompt
      final prompt = _buildAnalysisPrompt(currentNote, candidates);

      // è°ƒç”¨ Chat API
      final response = await http
          .post(
            Uri.parse('$apiUrl/chat/completions'),
            headers: {
              'Content-Type': 'application/json',
              'Authorization': 'Bearer $apiKey',
            },
            body: json.encode({
              'model': model,
              'messages': [
                {'role': 'system', 'content': 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¬”è®°åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ç†è§£ç¬”è®°ä¹‹é—´çš„è¯­ä¹‰å…³è”ã€‚'},
                {
                  'role': 'user',
                  'content': prompt,
                }
              ],
              'temperature': 0.3,
            }),
          )
          .timeout(const Duration(seconds: 30));

      if (response.statusCode == 200) {
        final data = json.decode(utf8.decode(response.bodyBytes));
        final content = data['choices']?[0]?['message']?['content'] as String?;

        if (content != null) {
          return _parseAIResponse(content, candidates);
        }
      } else {
        debugPrint('âš ï¸ AIåˆ†æå¤±è´¥ (${response.statusCode})ï¼Œé™çº§ä¸ºæœ¬åœ°ç®—æ³•');
      }

      return _findByLocalAlgorithm(currentNote, allNotes, topK);
    } catch (e) {
      debugPrint('âŒ AIåˆ†æç­–ç•¥å¤±è´¥: $e');
      return _findByLocalAlgorithm(currentNote, allNotes, topK);
    }
  }

  /// æ„å»º AI åˆ†æçš„ prompt
  String _buildAnalysisPrompt(Note currentNote, List<Note> candidates) {
    final currentText = _cleanText(currentNote.content);
    final buffer = StringBuffer();

    buffer.writeln('ã€å½“å‰ç¬”è®°ã€‘');
    buffer.writeln(_truncateText(currentText, 500));
    buffer.writeln('\nã€å€™é€‰ç¬”è®°åˆ—è¡¨ã€‘');

    for (var i = 0; i < candidates.length; i++) {
      final candidateText = _cleanText(candidates[i].content);
      buffer.writeln('ID:${i + 1} | ${_truncateText(candidateText, 200)}');
    }

    buffer.writeln('\nã€ä»»åŠ¡è¦æ±‚ã€‘');
    buffer.writeln('è¯·åˆ†æå½“å‰ç¬”è®°ä¸å€™é€‰ç¬”è®°çš„è¯­ä¹‰ç›¸å…³æ€§ï¼Œæ‰¾å‡ºæœ€ç›¸å…³çš„5æ¡ç¬”è®°ã€‚');
    buffer.writeln('è€ƒè™‘å› ç´ ï¼šä¸»é¢˜ç›¸å…³æ€§ã€å†…å®¹å»¶ç»­æ€§ã€çŸ¥è¯†å…³è”æ€§ã€‚');
    buffer.writeln('è¾“å‡ºæ ¼å¼ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰ï¼š');
    buffer.writeln('ID:ç›¸å…³åº¦åˆ†æ•°(0-100)');
    buffer.writeln('ä¾‹å¦‚ï¼šID:3:95');
    buffer.writeln('åªè¾“å‡ºç»“æœï¼Œä¸è¦å…¶ä»–è§£é‡Šã€‚');

    return buffer.toString();
  }

  /// è§£æ AI è¿”å›çš„ç»“æœ
  List<RelatedNote> _parseAIResponse(String content, List<Note> candidates) {
    final results = <RelatedNote>[];
    final lines = content.split('\n');

    for (final line in lines) {
      // åŒ¹é…æ ¼å¼ï¼šID:3:95 æˆ– 3:95
      final match = RegExp(r'(?:ID:)?(\d+)[:\s]+(\d+)').firstMatch(line);
      if (match != null) {
        final id = int.tryParse(match.group(1) ?? '');
        final score = int.tryParse(match.group(2) ?? '');

        if (id != null &&
            score != null &&
            id > 0 &&
            id <= candidates.length &&
            score >= 50) {
          final note = candidates[id - 1];
          results.add(
            RelatedNote(
              note: note,
              similarity: score / 100.0,
            ),
          );
        }
      }
    }

    results.sort((a, b) => b.similarity.compareTo(a.similarity));
    return results;
  }

  /// ç­–ç•¥3ï¼šæœ¬åœ°ç®—æ³•ï¼ˆé™çº§æ–¹æ¡ˆï¼‰- ğŸ”¥ ä½¿ç”¨å¤§å‚çº§å¤šç»´åº¦ç®—æ³•
  List<RelatedNote> _findByLocalAlgorithm(
    Note currentNote,
    List<Note> allNotes,
    int topK,
  ) {
    debugPrint('ğŸ“Š ä½¿ç”¨å¤§å‚çº§å¤šç»´åº¦ç®—æ³•ï¼ˆTF-IDF + é“¾æ¥åˆ†æ + æ—¶é—´è¡°å‡ï¼‰');
    
    // ä½¿ç”¨æ”¹è¿›çš„ç®—æ³•
    return _findByAdvancedAlgorithm(currentNote, allNotes, topK);
  }
  
  /// ğŸ¢ å¤§å‚çº§å¤šç»´åº¦ç®—æ³•ï¼ˆå‚è€ƒ Notion/Obsidianï¼‰
  List<RelatedNote> _findByAdvancedAlgorithm(
    Note currentNote,
    List<Note> allNotes,
    int topK,
  ) {
    final results = <RelatedNote>[];
    final currentText = _cleanText(currentNote.content);
    final currentTags = currentNote.tags.toSet();
    final currentLinks = _extractLinks(currentNote.content);
    
    // ğŸ”¥ æ„å»º TF-IDF æ¨¡å‹
    final tfidfModel = _buildTFIDF(allNotes);
    final currentVector = tfidfModel[currentNote.id] ?? {};
    
    for (final note in allNotes) {
      if (note.id == currentNote.id || note.content.trim().isEmpty) continue;
      
      final noteText = _cleanText(note.content);
      final noteTags = note.tags.toSet();
      final noteLinks = _extractLinks(note.content);
      final noteVector = tfidfModel[note.id] ?? {};
      
      // ğŸ¯ å¤šç»´åº¦è¯„åˆ†
      final contentScore = _calculateTFIDFSimilarity(currentVector, noteVector);
      final tagScore = _calculateTagSimilarity(currentTags, noteTags);
      final linkScore = _calculateLinkSimilarity(
        currentNote.id,
        note.id,
        currentLinks,
        noteLinks,
      );
      final timeScore = _calculateTimeScore(note.updatedAt);
      
      // ğŸ”¥ åŠ æƒè®¡ç®—æœ€ç»ˆåˆ†æ•°
      final finalScore = contentScore * 0.4 +
          tagScore * 0.25 +
          linkScore * 0.25 +
          timeScore * 0.1;
      
      if (finalScore > 0.3) {
        results.add(RelatedNote(note: note, similarity: finalScore));
      }
    }
    
    results.sort((a, b) => b.similarity.compareTo(a.similarity));
    
    if (kDebugMode && results.isNotEmpty) {
      debugPrint('âœ… æ‰¾åˆ° ${results.length} æ¡ç›¸å…³ç¬”è®°');
      debugPrint('ğŸ“Š Top 3: ${results.take(3).map((r) => '${(r.similarity * 100).toStringAsFixed(0)}%').join(', ')}');
    }
    
    return results.take(topK).toList();
  }
  
  /// ğŸ“Š æ„å»º TF-IDF æ¨¡å‹
  Map<String, Map<String, double>> _buildTFIDF(List<Note> allNotes) {
    final documentFreq = <String, int>{};
    final termFreqs = <String, Map<String, int>>{};
    
    // ç»Ÿè®¡è¯é¢‘
    for (final note in allNotes) {
      final text = _cleanText(note.content);
      final terms = _extractKeywords(text);
      final uniqueTerms = terms.toSet();
      
      for (final term in uniqueTerms) {
        documentFreq[term] = (documentFreq[term] ?? 0) + 1;
      }
      
      final tf = <String, int>{};
      for (final term in terms) {
        tf[term] = (tf[term] ?? 0) + 1;
      }
      termFreqs[note.id] = tf;
    }
    
    // è®¡ç®— TF-IDF
    final tfidf = <String, Map<String, double>>{};
    final totalDocs = allNotes.length;
    
    for (final note in allNotes) {
      final tf = termFreqs[note.id] ?? {};
      final vector = <String, double>{};
      
      for (final entry in tf.entries) {
        final term = entry.key;
        final termFreq = entry.value;
        final docFreq = documentFreq[term] ?? 1;
        final tfidfScore = termFreq * log(totalDocs / docFreq);
        vector[term] = tfidfScore;
      }
      
      tfidf[note.id] = vector;
    }
    
    return tfidf;
  }
  
  /// ğŸ¯ è®¡ç®— TF-IDF ä½™å¼¦ç›¸ä¼¼åº¦
  double _calculateTFIDFSimilarity(
    Map<String, double> vector1,
    Map<String, double> vector2,
  ) {
    if (vector1.isEmpty || vector2.isEmpty) return 0.0;
    
    var dotProduct = 0.0;
    var norm1 = 0.0;
    var norm2 = 0.0;
    
    for (final term in vector1.keys) {
      final v1 = vector1[term]!;
      final v2 = vector2[term] ?? 0.0;
      dotProduct += v1 * v2;
      norm1 += v1 * v1;
    }
    
    for (final v2 in vector2.values) {
      norm2 += v2 * v2;
    }
    
    norm1 = sqrt(norm1);
    norm2 = sqrt(norm2);
    
    if (norm1 == 0 || norm2 == 0) return 0.0;
    return dotProduct / (norm1 * norm2);
  }
  
  /// ğŸ·ï¸ è®¡ç®—æ ‡ç­¾ç›¸ä¼¼åº¦
  double _calculateTagSimilarity(Set<String> tags1, Set<String> tags2) {
    if (tags1.isEmpty && tags2.isEmpty) return 0.0;
    final intersection = tags1.intersection(tags2);
    final union = tags1.union(tags2);
    return union.isEmpty ? 0.0 : intersection.length / union.length;
  }
  
  /// ğŸ”— è®¡ç®—é“¾æ¥ç›¸ä¼¼åº¦
  double _calculateLinkSimilarity(
    String noteId1,
    String noteId2,
    Set<String> links1,
    Set<String> links2,
  ) {
    // ç›´æ¥é“¾æ¥
    if (links1.contains(noteId2) || links2.contains(noteId1)) {
      return 1.0;
    }
    
    // å…±åŒé“¾æ¥
    final commonLinks = links1.intersection(links2);
    if (commonLinks.isNotEmpty) {
      final allLinks = links1.union(links2);
      return commonLinks.length / allLinks.length * 0.8;
    }
    
    return 0.0;
  }
  
  /// â° æ—¶é—´æ–°é²œåº¦
  double _calculateTimeScore(DateTime noteTime) {
    final daysDiff = DateTime.now().difference(noteTime).inDays;
    if (daysDiff <= 7) return 1.0;
    if (daysDiff <= 30) return 0.7;
    if (daysDiff <= 90) return 0.4;
    if (daysDiff <= 180) return 0.2;
    return 0.1;
  }
  
  /// ğŸ”— æå–é“¾æ¥å¼•ç”¨
  Set<String> _extractLinks(String content) {
    final links = <String>{};
    final pattern = RegExp(r'\[\[([^\]]+)\]\]');
    for (final match in pattern.allMatches(content)) {
      final link = match.group(1);
      if (link != null && link.isNotEmpty) {
        links.add(link);
      }
    }
    return links;
  }

  /// æå–å…³é”®è¯
  List<String> _extractKeywords(String text) {
    final words = text
        .toLowerCase()
        .replaceAll(RegExp(r'[^\w\s\u4e00-\u9fa5]'), ' ')
        .split(RegExp(r'\s+'))
        .where((word) => word.length > 1)
        .where((word) => !_isStopWord(word))
        .toList();

    final wordFreq = <String, int>{};
    for (final word in words) {
      wordFreq[word] = (wordFreq[word] ?? 0) + 1;
    }

    final keywords = wordFreq.entries.toList()
      ..sort((a, b) => b.value.compareTo(a.value));

    return keywords.take(50).map((e) => e.key).toList();
  }

  /// åˆ¤æ–­åœç”¨è¯
  bool _isStopWord(String word) {
    const stopWords = {
      'the',
      'is',
      'at',
      'which',
      'on',
      'a',
      'an',
      'and',
      'or',
      'but',
      'in',
      'with',
      'to',
      'for',
      'of',
      'as',
      'by',
      'this',
      'that',
      'çš„',
      'äº†',
      'å’Œ',
      'æ˜¯',
      'åœ¨',
      'æˆ‘',
      'æœ‰',
      'ä¸ª',
      'å°±',
      'ä¸',
      'äºº',
      'éƒ½',
      'ä¸€',
      'ä¸€ä¸ª',
      'ä¸Š',
      'ä¹Ÿ',
      'å¾ˆ',
      'åˆ°',
      'è¯´',
      'è¦',
    };
    return stopWords.contains(word);
  }


  /// è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
  double _cosineSimilarity(List<double> a, List<double> b) {
    if (a.length != b.length) return 0;

    var dotProduct = 0.0;
    var normA = 0.0;
    var normB = 0.0;

    for (var i = 0; i < a.length; i++) {
      dotProduct += a[i] * b[i];
      normA += a[i] * a[i];
      normB += b[i] * b[i];
    }

    normA = sqrt(normA);
    normB = sqrt(normB);

    if (normA == 0 || normB == 0) return 0;
    return dotProduct / (normA * normB);
  }

  /// æ¸…ç†æ–‡æœ¬
  String _cleanText(String content) {
    var cleaned = content;

    // æ¸…ç† Markdown é“¾æ¥ï¼š[æ–‡æœ¬](url) -> æ–‡æœ¬
    cleaned = cleaned.replaceAllMapped(
      RegExp(r'\[([^\]]+)\]\([^\)]+\)'),
      (match) => match.group(1) ?? '',
    );

    // æ¸…ç† Markdown æ ¼å¼æ ‡è®°
    cleaned = cleaned.replaceAll(RegExp('[*_`#~]'), '');

    // æ¸…ç†å¤šä½™çš„ç©ºç™½
    cleaned = cleaned.replaceAll(RegExp(r'\n+'), ' ');
    cleaned = cleaned.replaceAll(RegExp(r'\s+'), ' ');

    return cleaned.trim();
  }

  /// æˆªæ–­æ–‡æœ¬
  String _truncateText(String text, int maxLength) {
    if (text.length <= maxLength) return text;
    return '${text.substring(0, maxLength)}...';
  }

  /// ç¼“å­˜ç»“æœ
  Future<void> _cacheResult(String key, List<RelatedNote> notes) async {
    try {
      final prefs = await SharedPreferences.getInstance();
      final cacheKey = '$_cachePrefix$key';
      final data = notes
          .map(
            (n) => {
              'id': n.note.id,
              'similarity': n.similarity,
            },
          )
          .toList();
      await prefs.setString(cacheKey, json.encode(data));
      await prefs.setInt(
        '${cacheKey}_time',
        DateTime.now().millisecondsSinceEpoch,
      );
    } catch (e) {
      debugPrint('âš ï¸ ç¼“å­˜å¤±è´¥: $e');
    }
  }

  /// è·å–ç¼“å­˜
  Future<List<Map<String, dynamic>>?> _getCachedResult(String key) async {
    try {
      final prefs = await SharedPreferences.getInstance();
      final cacheKey = '$_cachePrefix$key';
      final data = prefs.getString(cacheKey);
      final timestamp = prefs.getInt('${cacheKey}_time');

      if (data == null || timestamp == null) return null;

      final cacheTime = DateTime.fromMillisecondsSinceEpoch(timestamp);
      if (DateTime.now().difference(cacheTime) > _cacheExpiry) {
        await prefs.remove(cacheKey);
        await prefs.remove('${cacheKey}_time');
        return null;
      }

      return List<Map<String, dynamic>>.from(json.decode(data));
    } catch (e) {
      return null;
    }
  }

  /// è§£æç¼“å­˜çš„ç¬”è®°
  List<RelatedNote> _parseRelatedNotes(
    List<Map<String, dynamic>> cached,
    List<Note> allNotes,
  ) {
    final results = <RelatedNote>[];
    for (final item in cached) {
      final note = allNotes.firstWhere(
        (n) => n.id == item['id'],
        orElse: () => Note(
          id: '',
          content: '',
          createdAt: DateTime.now(),
          updatedAt: DateTime.now(),
        ),
      );
      if (note.id.isNotEmpty) {
        results.add(
          RelatedNote(
            note: note,
            similarity: item['similarity'] ?? 0.0,
          ),
        );
      }
    }
    return results;
  }

  /// æ¸…é™¤ç¼“å­˜
  Future<void> clearCache() async {
    try {
      final prefs = await SharedPreferences.getInstance();
      final keys = prefs.getKeys();
      for (final key in keys) {
        if (key.startsWith(_cachePrefix)) {
          await prefs.remove(key);
        }
      }
    } catch (e) {
      debugPrint('âš ï¸ æ¸…é™¤ç¼“å­˜å¤±è´¥: $e');
    }
  }
}

/// ç›¸å…³ç¬”è®°æ¨¡å‹
class RelatedNote {
  RelatedNote({
    required this.note,
    required this.similarity,
  });
  final Note note;
  final double similarity;

  int get similarityPercent => (similarity * 100).round();
}
